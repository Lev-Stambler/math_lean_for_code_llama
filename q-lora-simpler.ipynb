{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  import Mathlib.Tactic.Abel\\nimport Mathlib.Tac...\n",
      "1  /-\\nCopyright (c) 2020 Thomas Browning and Pat...\n",
      "2  /-\\nCopyright (c) 2021 Anne Baanen. All rights...\n",
      "3  /-\\nCopyright (c) 2018 Kenny Lau. All rights r...\n",
      "4  /-\\nCopyright (c) 2019 Johan Commelin. All rig...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def prepare_dataset(path, suffix='.lean'):\n",
    "    \"\"\"\n",
    "    Prepares an unsupervised dataset from files with a specific suffix in the given directory and its subdirectories.\n",
    "    \n",
    "    Parameters:\n",
    "    - path (str): The directory path to look for files.\n",
    "    - suffix (str): The file suffix to filter by. Default is '.txt'.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with a single 'text' column containing the content of each file.\n",
    "    \"\"\"\n",
    "\n",
    "    # List for storing file contents\n",
    "    texts = []\n",
    "\n",
    "    # Walking through the directory and its subdirectories\n",
    "    for dirpath, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(suffix):\n",
    "                with open(os.path.join(dirpath, filename), 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                    content = file.read()\n",
    "                    texts.append(content)\n",
    "\n",
    "    # Convert list of texts to a pandas DataFrame\n",
    "    df = pd.DataFrame(texts, columns=['text'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "# path = input(\"Enter the path: \")\n",
    "path = '../../../lean/mathlib4/Mathlib/'\n",
    "# suffix = input(\"Enter the file suffix (default is .txt): \")\n",
    "# if not suffix:\n",
    "#     suffix = '.txt'\n",
    "\n",
    "df = prepare_dataset(path, \"lean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, CodeLlamaTokenizer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def prepare_next_token_dataset(path, tokenizer, suffix='.txt', MAX_CONTENT_LENGTH=512, MIN_LENGTH=128):\n",
    "    \"\"\"\n",
    "    Prepares a dataset for next token prediction from files with a specific suffix in the given directory and its subdirectories.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The directory path to look for files.\n",
    "    - tokenizer: Tokenizer from the transformers library.\n",
    "    - suffix (str): The file suffix to filter by. Default is '.txt'.\n",
    "    - MAX_CONTENT_LENGTH (int): The maximum length for the input content.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with 'input' and 'target' columns for next token prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    # Lists for storing input sequences and target tokens\n",
    "    inputs = []\n",
    "    targets = []\n",
    "\n",
    "    # Walking through the directory and its subdirectories\n",
    "    for dirpath, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(suffix):\n",
    "                with open(os.path.join(dirpath, filename), 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                    content = file.read()\n",
    "                    # Tokenize the content using the provided tokenizer\n",
    "                    tokens = tokenizer.tokenize(content)\n",
    "                    for i in range(0, len(tokens) - MIN_LENGTH - 1):  # -1 to leave space for the target token\n",
    "                        input_sequence = tokens[i:min(i + MAX_CONTENT_LENGTH, len(tokens))]\n",
    "                        target_token = tokens[min(i + MAX_CONTENT_LENGTH, len(tokens) - 1)]\n",
    "                        inputs.append(tokenizer.convert_tokens_to_string(input_sequence))\n",
    "                        targets.append(target_token)\n",
    "\n",
    "    # Convert lists of inputs and targets to a pandas DataFrame\n",
    "    df = pd.DataFrame({'input': inputs, 'target': targets})\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "# path = input(\"Enter the path: \")\n",
    "# suffix = input(\"Enter the file suffix (default is .txt): \")\n",
    "# if not suffix:\n",
    "#     suffix = '.txt'\n",
    "\n",
    "# You can initialize the tokenizer here. For example, for BERT:\n",
    "tokenizer = CodeLlamaTokenizer.from_pretrained(\"codellama/CodeLlama-7b-hf\")\n",
    "\n",
    "path = '../../../lean/mathlib4/Mathlib/'\n",
    "\n",
    "MAX_CONTENT_LENGTH=2_048\n",
    "df = prepare_next_token_dataset(path, tokenizer, \".lean\", MAX_CONTENT_LENGTH, MIN_LENGTH=128)\n",
    "print(df.head())\n",
    "\n",
    "# If you want to save the DataFrame to a CSV:\n",
    "# df.to_csv('next_token_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁import</td>\n",
       "      <td>▁Math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁Math</td>\n",
       "      <td>lib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lib</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>actic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23008322</th>\n",
       "      <td>&lt;0x0A&gt;</td>\n",
       "      <td>&lt;0x0A&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23008323</th>\n",
       "      <td>&lt;0x0A&gt;</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23008324</th>\n",
       "      <td>end</td>\n",
       "      <td>▁First</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23008325</th>\n",
       "      <td>▁First</td>\n",
       "      <td>Order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23008326</th>\n",
       "      <td>Order</td>\n",
       "      <td>&lt;0x0A&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23008327 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            input  target\n",
       "0         ▁import   ▁Math\n",
       "1           ▁Math     lib\n",
       "2             lib       .\n",
       "3               .       T\n",
       "4               T   actic\n",
       "...           ...     ...\n",
       "23008322   <0x0A>  <0x0A>\n",
       "23008323   <0x0A>     end\n",
       "23008324      end  ▁First\n",
       "23008325   ▁First   Order\n",
       "23008326    Order  <0x0A>\n",
       "\n",
       "[23008327 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3528"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.get(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fastai in /home/lev/.local/lib/python3.9/site-packages (2.7.12)\n",
      "Requirement already satisfied: pip in /home/lev/.local/lib/python3.9/site-packages (from fastai) (23.2.1)\n",
      "Requirement already satisfied: packaging in /home/lev/.local/lib/python3.9/site-packages (from fastai) (23.1)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /home/lev/.local/lib/python3.9/site-packages (from fastai) (0.0.7)\n",
      "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /home/lev/.local/lib/python3.9/site-packages (from fastai) (1.5.29)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /home/lev/.local/lib/python3.9/site-packages (from fastai) (0.15.2)\n",
      "Requirement already satisfied: matplotlib in /home/lev/.local/lib/python3.9/site-packages (from fastai) (3.7.2)\n",
      "Requirement already satisfied: pandas in /home/lev/.local/lib/python3.9/site-packages (from fastai) (2.1.0)\n",
      "Requirement already satisfied: requests in /home/lev/.local/lib/python3.9/site-packages (from fastai) (2.31.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from fastai) (5.4.1)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /home/lev/.local/lib/python3.9/site-packages (from fastai) (1.0.3)\n",
      "Requirement already satisfied: pillow>6.0.0 in /home/lev/.local/lib/python3.9/site-packages (from fastai) (10.0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/lev/.local/lib/python3.9/site-packages (from fastai) (1.3.0)\n",
      "Requirement already satisfied: scipy in /home/lev/.local/lib/python3.9/site-packages (from fastai) (1.11.2)\n",
      "Requirement already satisfied: spacy<4 in /home/lev/.local/lib/python3.9/site-packages (from fastai) (3.6.1)\n",
      "Requirement already satisfied: torch<2.1,>=1.7 in /home/lev/.local/lib/python3.9/site-packages (from fastai) (2.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (1.24.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<4->fastai) (59.6.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/lev/.local/lib/python3.9/site-packages (from spacy<4->fastai) (3.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lev/.local/lib/python3.9/site-packages (from requests->fastai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->fastai) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->fastai) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->fastai) (2020.6.20)\n",
      "Requirement already satisfied: filelock in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (1.12)\n",
      "Requirement already satisfied: networkx in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/lev/.local/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (2.0.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=1.7->fastai) (0.37.1)\n",
      "Requirement already satisfied: cmake in /home/lev/.local/lib/python3.9/site-packages (from triton==2.0.0->torch<2.1,>=1.7->fastai) (3.27.2)\n",
      "Requirement already satisfied: lit in /home/lev/.local/lib/python3.9/site-packages (from triton==2.0.0->torch<2.1,>=1.7->fastai) (16.0.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/lev/.local/lib/python3.9/site-packages (from matplotlib->fastai) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/lev/.local/lib/python3.9/site-packages (from matplotlib->fastai) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/lev/.local/lib/python3.9/site-packages (from matplotlib->fastai) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/lev/.local/lib/python3.9/site-packages (from matplotlib->fastai) (1.4.5)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/lev/.local/lib/python3.9/site-packages (from matplotlib->fastai) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/lev/.local/lib/python3.9/site-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/lev/.local/lib/python3.9/site-packages (from matplotlib->fastai) (6.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->fastai) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/lev/.local/lib/python3.9/site-packages (from pandas->fastai) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/lev/.local/lib/python3.9/site-packages (from scikit-learn->fastai) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/lev/.local/lib/python3.9/site-packages (from scikit-learn->fastai) (3.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/lev/.local/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->fastai) (3.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/lev/.local/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/lev/.local/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/lev/.local/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/lev/.local/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<4->fastai) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/lev/.local/lib/python3.9/site-packages (from jinja2->spacy<4->fastai) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/lev/.local/lib/python3.9/site-packages (from sympy->torch<2.1,>=1.7->fastai) (1.3.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.6.5 has a non-standard dependency specifier torch>=1.8.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TextBlock' from 'fastai.text' (/home/lev/.local/lib/python3.9/site-packages/fastai/text/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/lev/code/research/ai/code_llama_lean/q-lora-simpler.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdebian-desktop/home/lev/code/research/ai/code_llama_lean/q-lora-simpler.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfastai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m \u001b[39mimport\u001b[39;00m TextBlock\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'TextBlock' from 'fastai.text' (/home/lev/.local/lib/python3.9/site-packages/fastai/text/__init__.py)"
     ]
    }
   ],
   "source": [
    "from fastai.text import TextBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#0) []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai\n",
    "print(fastai.__version__)\n",
    "from fastai.text import *\n",
    "from fastai.text.data import TextBlock, TextDataLoaders\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to your data\n",
    "path = Path('../../../lean/mathlib4/Mathlib/')\n",
    "\n",
    "# Create a DataBunch suitable for language modeling\n",
    "data_lm = TextBlock.from_folder(path, extensions=['.lean'], is_lm=True)\n",
    "          #  .filter_by_folder(include=['.lean'])  # Include all files in the root directory of 'path'\n",
    "          #  .split_by_rand_pct(0.1)  # Randomly split 10% of data for validation\n",
    "          #  .label_for_lm()  # Use this method for a language model\n",
    "          #  .databunch(bs=64, num_workers=1))\n",
    "\n",
    "# data_lm.save('data_lm.pkl')\n",
    "# print(data_lm).\n",
    "# dls = data_lmh.dataloaders(df, bs=64)\n",
    "data_lm.batch_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lev/code/research/ai/code_llama_lean/q-lora-simpler.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdebian-desktop/home/lev/code/research/ai/code_llama_lean/q-lora-simpler.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# https://docs.fast.ai/text.data.html#textdataloaders.from_folder\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdebian-desktop/home/lev/code/research/ai/code_llama_lean/q-lora-simpler.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m TextDataLoaders\u001b[39m.\u001b[39;49mfrom_folder(path, train\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, valid\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/text/data.py:262\u001b[0m, in \u001b[0;36mTextDataLoaders.from_folder\u001b[0;34m(cls, path, train, valid, valid_pct, seed, vocab, text_vocab, is_lm, tok_tfm, seq_len, splitter, backwards, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m get_items \u001b[39m=\u001b[39m partial(get_text_files, folders\u001b[39m=\u001b[39m[train,valid]) \u001b[39mif\u001b[39;00m valid_pct \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m get_text_files\n\u001b[1;32m    258\u001b[0m dblock \u001b[39m=\u001b[39m DataBlock(blocks\u001b[39m=\u001b[39mblocks,\n\u001b[1;32m    259\u001b[0m                    get_items\u001b[39m=\u001b[39mget_items,\n\u001b[1;32m    260\u001b[0m                    splitter\u001b[39m=\u001b[39msplitter,\n\u001b[1;32m    261\u001b[0m                    get_y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m is_lm \u001b[39melse\u001b[39;00m parent_label)\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_dblock(dblock, path, path\u001b[39m=\u001b[39;49mpath, seq_len\u001b[39m=\u001b[39;49mseq_len, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/data/core.py:284\u001b[0m, in \u001b[0;36mDataLoaders.from_dblock\u001b[0;34m(cls, dblock, source, path, bs, val_bs, shuffle, device, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_dblock\u001b[39m(\u001b[39mcls\u001b[39m, \n\u001b[1;32m    275\u001b[0m     dblock, \u001b[39m# `DataBlock` object\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    283\u001b[0m ):\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m dblock\u001b[39m.\u001b[39;49mdataloaders(source, path\u001b[39m=\u001b[39;49mpath, bs\u001b[39m=\u001b[39;49mbs, val_bs\u001b[39m=\u001b[39;49mval_bs, shuffle\u001b[39m=\u001b[39;49mshuffle, device\u001b[39m=\u001b[39;49mdevice, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/data/block.py:155\u001b[0m, in \u001b[0;36mDataBlock.dataloaders\u001b[0;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdataloaders\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[1;32m    150\u001b[0m     source, \u001b[39m# The data source\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     path:\u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m# Data source and default `Learner` path \u001b[39;00m\n\u001b[1;32m    152\u001b[0m     verbose:\u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m# Show verbose messages\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    154\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataLoaders:\n\u001b[0;32m--> 155\u001b[0m     dsets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets(source, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    156\u001b[0m     kwargs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, \u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m: verbose}\n\u001b[1;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m dsets\u001b[39m.\u001b[39mdataloaders(path\u001b[39m=\u001b[39mpath, after_item\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_tfms, after_batch\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_tfms, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/data/block.py:147\u001b[0m, in \u001b[0;36mDataBlock.datasets\u001b[0;34m(self, source, verbose)\u001b[0m\n\u001b[1;32m    145\u001b[0m splits \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplitter \u001b[39mor\u001b[39;00m RandomSplitter())(items)\n\u001b[1;32m    146\u001b[0m pv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(splits)\u001b[39m}\u001b[39;00m\u001b[39m datasets of sizes \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(s))\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39ms\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39msplits])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, verbose)\n\u001b[0;32m--> 147\u001b[0m \u001b[39mreturn\u001b[39;00m Datasets(items, tfms\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_combine_type_tfms(), splits\u001b[39m=\u001b[39;49msplits, dl_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdl_type, n_inp\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_inp, verbose\u001b[39m=\u001b[39;49mverbose)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/data/core.py:454\u001b[0m, in \u001b[0;36mDatasets.__init__\u001b[0;34m(self, items, tfms, tls, n_inp, dl_type, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[1;32m    446\u001b[0m     items:\u001b[39mlist\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m# List of items to create `Datasets`\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     tfms:MutableSequence\u001b[39m|\u001b[39mPipeline\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m# List of `Transform`(s) or `Pipeline` to apply\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    452\u001b[0m ):\n\u001b[1;32m    453\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(dl_type\u001b[39m=\u001b[39mdl_type)\n\u001b[0;32m--> 454\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls \u001b[39m=\u001b[39m L(tls \u001b[39mif\u001b[39;00m tls \u001b[39melse\u001b[39;00m [TfmdLists(items, t, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m L(ifnone(tfms,[\u001b[39mNone\u001b[39;00m]))])\n\u001b[1;32m    455\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_inp \u001b[39m=\u001b[39m ifnone(n_inp, \u001b[39mmax\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/data/core.py:454\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[1;32m    446\u001b[0m     items:\u001b[39mlist\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m# List of items to create `Datasets`\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     tfms:MutableSequence\u001b[39m|\u001b[39mPipeline\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m# List of `Transform`(s) or `Pipeline` to apply\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    452\u001b[0m ):\n\u001b[1;32m    453\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(dl_type\u001b[39m=\u001b[39mdl_type)\n\u001b[0;32m--> 454\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls \u001b[39m=\u001b[39m L(tls \u001b[39mif\u001b[39;00m tls \u001b[39melse\u001b[39;00m [TfmdLists(items, t, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m L(ifnone(tfms,[\u001b[39mNone\u001b[39;00m]))])\n\u001b[1;32m    455\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_inp \u001b[39m=\u001b[39m ifnone(n_inp, \u001b[39mmax\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fastcore/foundation.py:98\u001b[0m, in \u001b[0;36m_L_Meta.__call__\u001b[0;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(x,\u001b[39mcls\u001b[39m): \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/data/core.py:368\u001b[0m, in \u001b[0;36mTfmdLists.__init__\u001b[0;34m(self, items, tfms, use_list, do_setup, split_idx, train_setup, splits, types, verbose, dl_type)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mif\u001b[39;00m do_setup:\n\u001b[1;32m    367\u001b[0m     pv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSetting up \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfms\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, verbose)\n\u001b[0;32m--> 368\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(train_setup\u001b[39m=\u001b[39;49mtrain_setup)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/data/core.py:397\u001b[0m, in \u001b[0;36mTfmdLists.setup\u001b[0;34m(self, train_setup)\u001b[0m\n\u001b[1;32m    395\u001b[0m         x \u001b[39m=\u001b[39m f(x)\n\u001b[1;32m    396\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtypes\u001b[39m.\u001b[39mappend(\u001b[39mtype\u001b[39m(x))\n\u001b[0;32m--> 397\u001b[0m types \u001b[39m=\u001b[39m L(t \u001b[39mif\u001b[39;00m is_listy(t) \u001b[39melse\u001b[39;00m [t] \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtypes)\u001b[39m.\u001b[39mconcat()\u001b[39m.\u001b[39munique()\n\u001b[1;32m    398\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpretty_types \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m  - \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m types])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# https://docs.fast.ai/text.data.html#textdataloaders.from_folder\n",
    "TextDataLoaders.from_folder(path, train='train', valid='valid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
